# sLBFGS
Java Implementation of Stochastic L-BFGS

This repository contains a Java 1.8 implementation of the stochastic optimizer described in the paper "A Linearly-Convergent Stochastic L-BFGS Algorithm" (http://arxiv.org/abs/1508.02087). It draws heavily on the Julia implementation from the original authors, which can be found here: https://github.com/pcmoritz/slbfgs. 

This implementation also has some modifications from the original:

- A simple and modular optimization framework: 
  - An abstract Model class where various loss functions can be implemented
  - A minimal superclass Minimizer that optimizes Models; subclasses specify the optimization method 
  - And a basic reporting framework (the Fit class) that is generated by Models and used by Minimizers
- Minor changes to the sL-BFGS algorithm:
  - A basic convergence criteria is tested at every epoch (after the computation of the full gradient)
  - A gradient 'conditioning' step is included for poorly behaved functions
  - The Hessian Vector Product step is replaced with a finite-difference approximation using the central difference method
- Multiple test cases:
  - Five non-stochastic test functions from https://en.wikipedia.org/wiki/Test_functions_for_optimization:
    - Beale's Function
    - Goldstein-Price Function
    - Matyas Function
    - Rosenbrock Function
    - Sphere Function
  - The simple SVM test case from the original Julia implementation; this test uses the first 10,000 datapoints in the 'adult' dataset from https://archive.ics.uci.edu/ml/machine-learning-databases/adult/.
